{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c18d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from etl import get_data, edit_graphtype, read_graph\n",
    "from get_result import get_result \n",
    "from IPython.display import display, Markdown, Latex, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0eec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files to obtain data\n",
    "filepath = get_data(is_notebook = True)\n",
    "# Get graph results\n",
    "edit_graphtype(filepath)\n",
    "graph, truth = read_graph(filepath)\n",
    "results = get_result(graph, truth)\n",
    "results = results.Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9c465",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Recent work introduced the vast unfolding of communities in large networks, in which a heuristic methodology not only identifies communities, but also measures the density between nodes in modules that highlight the strength of a subcommunity. It was shown that such methodology can facilitate community detection, and exceed similar community detection algorithms in time complexity. In this paper, we explore 3 popular clustering algorithms, which use simple metrics like the number of common neighbors. We show how a collection of nodes with a large number of common neighbors have a higher probability of being deemed a community. The selected algorithms are the Weighted Threshold, Louvain, and Girvan-Newman. These algorithms will be tested on a political blogs network and their performance will be measured using the max intersection accuracy. The results of the study showed that the Louvain algorithm performed the best, followed by the Weighted Threshold and Girvan-Newman algorithms which had the same max intersection accuracy. Further research is needed to determine the potential applications of these algorithms in the field of network analysis since we only used one network to evaluate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c765158",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Technological innovations during the past few decades, including the rise of computers, the internet, and social media, have accelerated the size and strength of data networks. When analyzing the data behind various data networks, communities form naturally within them through connections between individual points of data, or nodes. These communities are typically defined by a common variable such as physical location, political alignment, or interest in a public figure. However, as more individual nodes of data are added to the data collection, the number of connections between nodes and the number of communities formed to represent these connections grows exponentially, creating difficult problems to overcome when analyzing the data in a timely manner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8596800",
   "metadata": {},
   "source": [
    "\\\\\n",
    "\\\\\n",
    "It’s important to note that grouping data has always been a problem that we have been trying to solve, and has been done through clustering algorithms, where using multiple attributes for each data entry can be used to find similarities and differences between them to create “clusters”. However, the idea of locating and recovering communities is focused specifically on networks as analysis largely relies on a single attribute type - the edge. This is where the planted clique problem is presented: identifying the subset of nodes in a network that have something in common, all determined by edges. The challenge was constructing an algorithm to do so that could perform in efficient time. Methods to achieve this in polynomial time were introduced in 1995 by Luděk Kučera, and improved upon in 1998 by Alon, Krivelevich and Sudakov. Both of which proposed constraints to the size of the planted clique relative to the network, where the planted clique could be found with high probability. More recently, the paper \\cite{pmlr-v40-Hajek15} “Computational Lower Bounds for Community Detection on Random Graphs” observes that there are calculations to clearly define three bounds that determine the level of difficulty to retrieve a planted clique: simple, hard, and impossible. This prior research exposes a drawback in graph data, given that some situations cannot be optimized at all. \\\\\n",
    "\n",
    "\\begin{figure}[H]\n",
    "    \\begin{center}\n",
    "        \\includegraphics[width=10cm]{outputs/image1.png} \\\\\n",
    "        \\textbf{Figure 1: As seen, in \\cite{pmlr-v40-Hajek15} “The simple (green), hard (red), impossible (gray) regimes for recovering planted dense subgraphs, and the hardness in the blue regime remains open\"} \\\\\n",
    "    \\end{center}\n",
    "\\end{figure}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb4b3f",
   "metadata": {},
   "source": [
    "## Definition of Community Detection Algorithms\n",
    "\n",
    "\n",
    "Community detection, commonly referred to as graph clustering or network clustering, is a task in network analysis which is used to identify groups or communities within a given network. These groups are usually characteristic of dense connections between nodes within the group, as compared to the connections of these nodes to the nodes in the rest of the network.\n",
    "\n",
    "Community detection in a network is important and interesting because it can provide useful insights to the structural organization of a network that can be applied to many diverse real-world networks. Since there is a tremendous amount of information stored in each network, if we could detect communities in each network it would provide us with important information and allow the study of the network easier. Furthermore, it could help us improve efficiency for processing and analyzing network data. For example, in social media each user is a node, and the users’ friends whom they interact with form a connection and thus become a network. Social media companies could use community detection algorithms to keep people with common friends,common interests, and background tightly connected, so they could better personalize and establish a more efficient recommendation system and advertisements. By analyzing the existence of communities, we can also learn about the processes of how a network is spreading in various settings. Another useful and important application of community detection is the prediction of missing links and identifying false links in a network because of errors. By applying a community detection algorithm it would allow users to assign and fix these links.\n",
    "\n",
    "There are many different community detection algorithms, each with their own pros and cons. In this paper, we aim to explore and analyze the performance of 3 algorithms used for community detection on a single dataset. The algorithms we have chosen are:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af6ae8ae",
   "metadata": {},
   "source": [
    "\\begin{itemize} \\item \\textbf{Weighted Threshold algorithm}\\cite{threshold}, which uses a weight threshold to detect high-quality communities in networks with spread out edge weights\n",
    "\\item\\textbf{Louvain (Modularity) algorithm}\\cite{louvain}, which works by recursively optimizing a modularity measure to identify communities.\n",
    "\\item\\textbf{Girvan-Newman algorithm}\\cite{girvan_newman}, which uses ‘edge betweenness’ to identify communities with clear boundaries in networks.\n",
    "\\end{itemize}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671068b",
   "metadata": {},
   "source": [
    "These algorithms were chosen since they represent a range of different approaches to community detection and have also been extensively used in research. We will apply each of these algorithms on the same dataset, and use a fixed metric which measures the ability of each algorithm to identify communities accurately. The results of our analysis will be reported in the paper, along with a discussion of why a certain algorithm may have performed better. We hope that our work will provide insights into the strengths and weaknesses of the selected algorithms, and will help guide future research on community detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe661a5f",
   "metadata": {},
   "source": [
    "## Overview of Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "313c937e",
   "metadata": {},
   "source": [
    "The dataset\\cite{dataset} we chose contains a directed network of hyperlinks between weblogs on US politics from the year 2005, created by Lada A. Adamic and Natalie Glance. These hyperlinks were taken from top blog websites on politics which contained links to other blogs. The dataset consists of a set of nodes which represent the individual blogs, and a set of directed edges representing the links between the blogs. We chose this dataset to assess how the different selected algorithms perform at identifying communities from a real world dataset. The network contains a total of 1490 nodes and 19090 edges. The node values indicate political leaning as follows: \\\\"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c8f8be7",
   "metadata": {},
   "source": [
    "\\begin{table}[H]\n",
    "    \\begin{center}\n",
    "    \\begin{tabular}{||c c||}\n",
    "        \\hline\n",
    "        Label & Significance \\\\ [0.5ex] \\hline\\hline\n",
    "        0 & Left-wing or Liberal \\\\ \\hline\n",
    "        1 & Right-wing or Conservative \\\\ \\hline\n",
    "    \\end{tabular} \\linebreak[2]\n",
    "    \\textbf{Table 1: Dataset value labels}\n",
    "    \\end{center}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9a030",
   "metadata": {},
   "source": [
    "\n",
    "The actual number of nodes in the left and right wing parties are 758 and 732, respectively. A paper written by the creators of this dataset (Adamic and Glance) highlights how one of the main differences they found between the two communities or parties is how the right wing blogs had significantly more links to each other than the left wing. After performing some exploratory analysis on the dataset, we can see that this is true since the in-group degree of the conservative (right wing) blogs is far larger than the in-group degree for the liberal blogs. The in-group degree is a measure of the connections a particular node has with other nodes in the same community. The red points on Figure 1 indicate nodes that belong to the left wing community, and the purple nodes belong to the right wing community."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2905ff01",
   "metadata": {},
   "source": [
    "\\begin{figure}[H]\n",
    "    \\begin{center}\n",
    "        \\includegraphics[width=10cm]{outputs/image3.png} \\\\\n",
    "        \\textbf{Figure 2: A visualization of the graph.} \\\\\n",
    "    \\end{center}\n",
    "\\end{figure}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f039c98c",
   "metadata": {},
   "source": [
    "\\begin{table}[H]\n",
    "    \\begin{center}\n",
    "    \\hspace*{-1.5cm}\\begin{tabular}{||c c c c c c||}\n",
    "        \\hline\n",
    "        Label & Number of nodes & In-group degree & In-group probability & Out-group degree & Out-group probability \\\\ [0.5ex] \\hline\\hline\n",
    "        0 & 758 & 16816 & 0.029306 & 1688 & 0.003042 \\\\ \\hline\n",
    "        1 & 732 & 17988 & 0.033617 & 1688 & 0.003042 \\\\ \\hline\n",
    "    \\end{tabular} \\linebreak[2]\n",
    "    \\textbf{Table 2: Descriptive graph statistics of the blog dataset}\n",
    "    \\end{center}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096d131",
   "metadata": {},
   "source": [
    "\n",
    "# Algorithm Descriptions\n",
    "\n",
    "## Weighted Threshold\n",
    "\n",
    "The weighted threshold algorithm synthesizes both Depth First Search (DFS) and common neighbor counting to detect algorithms. Determining whether a pair of nodes belongs in the same community depends on a weighted threshold calculated from their degrees. The threshold is determined beforehand as a parameter input by the user, then it is used to decide if the number of common neighbors between two nodes is sufficient enough to categorize the two as being in the same community. This process is repeated for each pair of nodes until all nodes have been categorized into a community."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2550db",
   "metadata": {},
   "source": [
    "## Louvain\n",
    "\n",
    "The Louvain community detection algorithm is based upon a modularity approach. The algorithm compares the actual number of edges in a community to the expected number of edges in a community. The algorithm uses a recursive format to achieve maximum accuracy of community detection.\n",
    "\n",
    "The two step process assigns nodes to communities, then iteratively using a modularity approach to evaluate whether moving a node to another community has a positive increase in accuracy. If the algorithm detects a higher accuracy (“gain”), then the node is kept in its new community and the algorithm moves onto the next iterative node. However, if the algorithm detects a lower accuracy (“gain”), then the node is kept in its current community.\n",
    "\n",
    "This process repeats recursively until the accuracy (“gain”) of the model is no longer improved per recursive iteration.\n",
    "\n",
    "## Girvan-Newman\n",
    "\n",
    "The Girvan-Newman algorithm is a heuristic algorithm used to detect communities. It works by finding and removing the edges between the most central nodes in a network, such that the network forms smaller broken down communities. The central nodes in a network would be the nodes through which most other nodes need to pass through in order to find the shortest path to different nodes. This process of removing the edges between the most central nodes is continued until the desired number of communities is reached.\n",
    "\n",
    "The algorithm uses a measure called edge betweenness which is how often an edge in a network lies on the shortest path between two nodes. The Girvan-Newman algorithm first calculates the edge betweenness of each node in the network. Nodes with a higher edge betweenness are considered to be more important to connect different parts or clusters of the network.\n",
    "\n",
    "The algorithm then removes the edge of the node with the highest edge betweenness and breaks the network into two communities. The algorithm then recalculates the edge betweenness for the remaining nodes and edges and removes the next edge iteratively until the network is divided into the required number of communities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94d784b2",
   "metadata": {},
   "source": [
    "\\begin{figure}[H]\n",
    "    \\begin{center}\n",
    "        \\includegraphics[width=10cm]{outputs/image2.png} \\\\\n",
    "        \\textbf{Figure 3: A visualization\\cite{algorithms} of a sample graph to explain the Girvan-Newman algorithm.} \\\\\n",
    "    \\end{center}\n",
    "\\end{figure}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329ee5c",
   "metadata": {},
   "source": [
    "\n",
    "In this figure, the numbers next to each edge are the edge betweenness scores. So at this point in the algorithm (after the scores are calculated), the edge between the nodes C and D would be removed to form two communities on the left and right sides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ed6ea",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fbbc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Using the Political Blog dataset, we were able to get the following results:\\begin{table}[H]\\begin{center}\\begin{tabular}{||c c||} \\hline \n",
       "Algorithm & Accuracy \\\\ [0.5ex] \\hline\\hline Girvan-Newman & 0.6067 \\\\ \\hline \n",
       "Louvain & 0.9604 \\\\ \\hline \n",
       "Weighted Threshold & 0.6067 \\\\ \\hline \n",
       "\\end{tabular} \\linebreak[2] \\textbf{Table 3: The results of our analysis} \\end{center}\\end{table} "
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Latex(\n",
    "    \"Using the Political Blog dataset, we were able to get the following results:\" +\n",
    "    \"\\\\begin{table}[H]\\\\begin{center}\\\\begin{tabular}{||c c||} \\hline \\n\" +\n",
    "    \"Algorithm & Accuracy \\\\\\\\ [0.5ex] \\hline\\hline \" + \n",
    "    \"Girvan-Newman & \" + str(results.loc['girvan_newman'].round(4)) + \" \\\\\\\\ \\hline \\n\" + \n",
    "    \"Louvain & \" + str(results.loc['louvain'].round(4) ) + \" \\\\\\\\ \\hline \\n\" + \n",
    "    \"Weighted Threshold & \" + str(results.loc['weighted_threshold'].round(4)) + \" \\\\\\\\ \\hline \\n\" + \n",
    "    \"\\end{tabular} \\linebreak[2] \\\\textbf{Table 3: The results of our analysis} \\end{center}\\end{table} \"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c647c52",
   "metadata": {},
   "source": [
    "\n",
    "## Performance Metric for the Algorithms\n",
    "\n",
    "We decided to use a metric called the **maximum intersection accuracy** which is a measure of how well a clustering algorithm has identified the correct number of clusters and correctly assigned nodes to their actual communities. A high max intersection accuracy means that the algorithm has performed well in identifying the structure of a network, while a low max intersection accuracy indicates that the algorithm may have failed to accurately identify the communities. The max intersection accuracy can be used to effectively compare and evaluate the performance of the three selected algorithms.\n",
    "\n",
    "## Performance of the Weighted Threshold Algorithm\n",
    "\n",
    "The algorithm yielded a performance of about 60.6% for max intersection accuracy. This is no surprise, considering the fact that the dataset has an inner group probability of 0.0315, meaning there are less connections between nodes of the same cluster. Inevitably though, this is on par with the Girvan-Newman algorithm but not as efficient as the Louvain algorithm.\n",
    "\n",
    "\n",
    "## Performance of Louvain Algorithm\n",
    "\n",
    "The Louvain algorithm yielded a performance of 95.9% for max intersection accuracy. This is significantly higher than both the weighted threshold algorithm and the Girvan-Newman algorithm. Therefore, we can conclude that for this particular network that we tested the algorithms on, the Louvain algorithm is the most effective. \n",
    "\n",
    "## Performance of Girvan-Newman Algorithm\n",
    "\n",
    "The Girvan-Newman algorithm resulted in a max intersection accuracy of 60.6%. The max intersection accuracy was the same as the performance of the weighted threshold algorithm which could imply that both the algorithms are similar. It is possible that both these algorithms had similar performance since both algorithms use some form of a score related to the connectedness of nodes in a network. In the case of the Girvan-Newman algorithm, this score is the betweenness centrality of the edges, while the weighted threshold algorithm uses a score based on the weights of the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c5b02",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "## Strengths and Weaknesses of Each Algorithm\n",
    "\n",
    "### Weighted Threshold\n",
    "\n",
    "The weighted threshold algorithm depends on a high probability of connections within clusters because of its reliance on counting common neighbors. If the probability of a connection between nodes of the same cluster is low, that will inevitably result in the cluster also having a lower chance of having common neighbors between nodes. The weighted threshold’s relatively low accuracy is likely due to the fact that the political blogs network has an extremely low intra probability of 0.0315. If the in group probability were higher, the weighted threshold algorithm would likely perform better.\n",
    "\n",
    "### Louvain\n",
    "\n",
    "The Louvain algorithm's largest benefit is the ease of implementation and time efficiency of the algorithm to run. There are limited tweaks to be made to the model, which allows a user to easily implement it and optimize its runtime.\n",
    "\n",
    "On the other hand, the Louvain algorithm’s downfall is its high usage of system storage throughout the running of the model. This is due to the need to store communities and duplicate nodes between communities while running the recursive algorithm and placement of nodes.\n",
    "\n",
    "### Girvan-Newman\n",
    "\n",
    "The main benefit of using the Girvan-Newman algorithm is its simplicity. The algorithm only requires the calculation of the edge betweenness for each node and the removal of the edge with the highest edge betweenness. The formula to calculate the edge betweenness is also extremely trivial and easy to understand. This makes the algorithm particularly easy to implement and understand, even for people with little to no knowledge of graph theory. \n",
    "\n",
    "Another strength of this algorithm is its versatility and ability to be applied to a wide range of network types and sizes. It is a popular and well documented algorithm which has been widely used in research for the same reason.\n",
    "\n",
    "Despite its simplicity, running the Girvan-Newman algorithm on extremely large datasets would be computationally intense and hence, not ideal. Even though the calculation for the edge betweenness is simple, calculating this for every single node in a network would take time and resources. This can make the algorithm impractical to use on large datasets. Since the selected dataset had only 1490 nodes, the results of running the algorithm were almost immediate. \n",
    "\n",
    "Another limitation of the Girvan-Newman algorithm is its sensitivity to noise. The algorithm solely relies on the calculation of the edge betweenness, which can severely be affected by the presence of outliers or noisy data. This can lead to the formation of false communities and ultimately result in a worse accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc723eae",
   "metadata": {},
   "source": [
    "## Comparison of Results\n",
    "\n",
    "Both algorithms, Girvan-Newman Algorithm and Weighted Threshold, use these scores to identify and remove edges that are important for connecting different parts of the network, leading to the formation of clusters or communities. This could be why they both have the same max intersection accuracy in this particular case.\n",
    "However, it is important to note that the performance of these algorithms can vary depending on the specific dataset and the parameters used. Therefore, it is not always accurate to conclude that the algorithms are similar just based on their max intersection accuracy.\n",
    "\n",
    "The issue with the weighted threshold algorithm is, as stated before, that it relies on a high inner probability value to best take advantage of common neighbor counting. Because this dataset has a small intraprobability of 0.0315, the algorithm does not perform as well as one might expect, though still satisfactory, as it matches the performance of the Girvan-Newman algorithm.\n",
    "\n",
    "Problem with Girvan-Newman is that it is not ideal if we do not know the required number of communities, this can result in poor performance. After all, it is simple, but the lack of dependence on further information can yield an incorrect number of communities without that constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bcba6d",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Summary of Findings\n",
    "\n",
    "After testing different community detection algorithms on one dataset, the following findings were observed:\n",
    "\n",
    "1. The Louvain algorithm was found to be the most effective in identifying and dividing the network into clusters, with a max intersection accuracy of 95.9%\n",
    "2. The weighted threshold algorithm performed average, with a max intersection accuracy of 60.6%.\n",
    "3. The Girvan-Newman algorithm had the same accuracy as the weighted threshold algorithm.\n",
    "\n",
    "Overall, these findings suggest that different community detection algorithms can have varying performance depending on the specific dataset and parameters used. It is important to carefully evaluate the performance of different algorithms and select the one that is most appropriate for the specific application and dataset. As stated before, for this particular network of weblogs and hyperlinks, the Louvain algorithm was the most well-suited. Further testing and analysis are needed to determine its overall effectiveness in different scenarios.\n",
    "\n",
    "## Recommendations and Implications for Further Research\n",
    "\n",
    "Looking forward to future research, it's important to take what we have learned regarding the accuracy of each model and put it into practice and testing with larger datasets. Furthermore, it is recommended to run a comparison test using more than the two comparison communities (left wing vs right wing) that we utilized in this paper. These models and their accuracy are tested and maximized on comparing two communities, in which we found the Louvain algorithm to have the highest accuracy in predicting communities. However, with an increase in communities the other models may perform better or worse. Therefore the number of communities is one factor to test in future research.\n",
    "\n",
    "Furthermore, it would be interesting to include new models in comparison. Although we identified Louvain had a high accuracy, there may be other models that perform better that weren’t taken into consideration in this paper, such as the “Surprise Community Detection” model in the same NetworkX package as the three models researched in this paper.\n",
    "\n",
    "Taking a different approach, it may be interesting to take the Louvain algorithm and look at large datasets with multiple communities, and use the algorithm to identify unique communities. This is especially interesting in today’s world of social media applications and the data they collect. For example, one could find it interesting to utilize Louvain’s algorithm to identify communities in Tiktok to explore existing and possibly new minute communities. We have only scratched the surface into community detection algorithms, it is up to the scientific community to take our learnings to both leverage and improve them.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac9a43df",
   "metadata": {},
   "source": [
    "\\pagebreak\n",
    "\n",
    "\\begin{thebibliography}{1}\n",
    "\n",
    "\\bibitem{dataset} Adamic, L. A., \\& Glance, N. (2005). The political blogosphere and the 2004 U.S. election. Proceedings of the 3rd International Workshop on Link Discovery - LinkKDD '05. \\url{https://doi.org/10.1145/1134271.1134277}\n",
    "\n",
    "\\bibitem{pmlr-v40-Hajek15} Hajek, B., Wu, Y. \\& Xu, J.. (2015). Computational Lower Bounds for Community Detection on Random Graphs. Proceedings of The 28th Conference on Learning Theory, in Proceedings of Machine Learning Research 40:899-928 Available from \\url{https://proceedings.mlr.press/v40/Hajek15.html}.\n",
    "\n",
    "\\bibitem{algorithms} Jayawickrama, T. D. (2021, February 1). Community detection algorithms. Medium. Retrieved December 4, 2022, from \\url{https://towardsdatascience.com/community-detection-algorithms-9bd8951e7dae} \n",
    "\n",
    "\\bibitem{louvain} Louvain. Neo4j Graph Data Platform. (n.d.). Retrieved December 4, 2022, from \\url{https://neo4j.com/docs/graph-data-science/current/algorithms/louvain/}\n",
    "\n",
    "\\bibitem{girvan_newman} Memgraph. (n.d.). Girvan-Newman algorithm. NetworkX Guide. Retrieved December 4, 2022, from \\url{https://networkx.guide/algorithms/community-detection/girvan-newman/} \n",
    "\n",
    "\\bibitem{threshold} Yan, X., Jeub, L. G., Flammini, A., Radicchi, F., \\& Fortunato, S. (2018). Weight Thresholding on complex networks. Physical Review E, 98(4). \\url{https://doi.org/10.1103/physreve.98.042304} \n",
    "\n",
    "\\end{thebibliography}"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Kudsi, M; Li, Y; Nguyen, J; Rayalu, V; Stassinopoulos, A; Wang, F"
   }
  ],
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "title": "Performance Evaluation of Clustering Algorithms on a Network of Political Blogs",
  "vscode": {
   "interpreter": {
    "hash": "0fd178b88fe9aab8671e4dbad5a437db91a73abc44bb831f68e3e650b6c433cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
